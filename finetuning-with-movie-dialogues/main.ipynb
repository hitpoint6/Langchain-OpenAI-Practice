{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a fine tune model from OpenAI Davinci"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape conversations from movie script"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to scrape the conversations into a data structure like below.\n",
    "\n",
    "The \\n\\n###\\n\\n and END is the separator to inform the model when the prompt or completion ends.\n",
    "\n",
    "The separators should not exist in the prompt or completion.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "[{\n",
    "  \"prompt\": \"USER: Hey, how are you?\\n\\n###\\n\\n\",\n",
    "  \"completion\": \"ASSISTANT: I'm good thank you!END\"}\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://imsdb.com/scripts/Her.html')\n",
    "html = response.content\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all Theodore and Samatha's conversations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "conversations = []\n",
    "b_tags = soup.find_all('b')\n",
    "for i in range(len(b_tags)):\n",
    "    tag = b_tags[i]\n",
    "    if tag and tag.string and tag.next_sibling is not None and tag.next_sibling.name != 'b':\n",
    "        conversation = {}\n",
    "        tag_string = tag.string.strip()\n",
    "        cleaned_message = tag.next_sibling.strip()\n",
    "        cleaned_message = cleaned_message.replace('\\r\\n', '')\n",
    "        cleaned_message = cleaned_message.replace('\\\\', '')\n",
    "        cleaned_message = re.sub(r'\\([^)]*\\)', '', cleaned_message)\n",
    "        cleaned_message = ' '.join(cleaned_message.split())\n",
    "        if tag_string.find('THEODORE') != -1:\n",
    "            conversation['THEODORE'] = cleaned_message\n",
    "        elif tag_string.find('SAMANTHA') != -1:\n",
    "            conversation['SAMANTHA'] = cleaned_message\n",
    "        if len(conversation) > 0:\n",
    "            conversations.append(conversation)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep all the conversations between the two characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_conversations = []\n",
    "for i in range(1, len(conversations), 2):\n",
    "    if 'THEODORE' in conversations[i - 1] and 'SAMANTHA' in conversations[i]:\n",
    "        ts_conversations.append(conversations[i-1])\n",
    "        ts_conversations.append(conversations[i])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add spearators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "for i in range(1, len(ts_conversations), 2):\n",
    "    data = {}\n",
    "    data[\"prompt\"] = f\"{''.join(ts_conversations[i-1].values())}\\n\\n###\\n\\n\"\n",
    "    data[\"completion\"] = f\" {''.join(ts_conversations[i].values())}END\"\n",
    "    training_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(training_data)\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save as jsonl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('training_data.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune the model with openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the data are properly formatted\n",
    "!openai tools fine_tunes.prepare_data -f training_data.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create find tuning\n",
    "!openai api fine_tunes.create -t training_data.jsonl -m davinci --suffix \"Her\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all your fine tuned models\n",
    "!openai api fine_tunes.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the status of the fine tuning model\n",
    "!openai api fine_tunes.get -i ft-f4gPZuStsshSbVaHx0lE6hlq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !openai api fine_tunes.cancel -i ft-GfxNi7ihj2VWIVtFFzrH7ia2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once training is finished. The model can be found in the playground: https://platform.openai.com/playground and it can be used in API calls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
